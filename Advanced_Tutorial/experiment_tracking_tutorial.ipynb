{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验跟踪与可视化教程 (TensorBoard, Weights & Biases, MLflow)\n",
    "\n",
    "欢迎来到机器学习实验跟踪与可视化教程！在进行机器学习项目时，有效地跟踪实验过程、记录关键指标和可视化结果对于保证可复现性、比较不同尝试的效果以及深入理解模型行为至关重要。\n",
    "\n",
    "本教程将分别介绍三个广泛使用的工具，它们各有侧重，但都能帮助你更好地管理和理解你的机器学习实验：\n",
    "\n",
    "1.  **TensorBoard**: Google 开发的可视化工具包，擅长实时监控训练指标、可视化模型图和数据，通常在本地运行。\n",
    "2.  **Weights & Biases (WandB)**: 一个流行的云平台（对个人和学术免费），提供实验跟踪、高级可视化、协作和模型管理功能。\n",
    "3.  **MLflow (Tracking 组件)**: 一个开源的端到端 MLOps 平台，其 Tracking 组件专注于记录和查询实验参数、指标、代码和模型，可本地或远程部署。\n",
    "\n",
    "我们将通过训练一个简单的 CNN 模型对 FashionMNIST 数据集进行分类的示例，分别展示如何集成和使用这三个工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作：安装必要的库\n",
    "\n",
    "请确保在运行相应部分之前已安装所需的库。\n",
    "\n",
    "```bash\n",
    "# 通用依赖\n",
    "pip install torch torchvision scikit-learn pandas matplotlib numpy\n",
    "\n",
    "# TensorBoard (如果尚未随 PyTorch/TensorFlow 安装)\n",
    "pip install tensorboard\n",
    "\n",
    "# Weights & Biases\n",
    "pip install wandb\n",
    "\n",
    "# MLflow\n",
    "pip install mlflow\n",
    "```\n",
    "\n",
    "**重要提示**: \n",
    "*   **WandB**: 需要注册免费账号并在首次使用时 `wandb login`。\n",
    "*   **MLflow**: 默认在本地 `./mlruns` 目录记录，可通过 `mlflow ui` 查看。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 TensorBoard 进行可视化\n",
    "\n",
    "TensorBoard 通过读取事件文件来可视化训练过程。PyTorch 提供了 `SummaryWriter` 来方便地生成这些文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TensorBoard: 导入与设置 ---\n",
    "print(\"--- Setting up for TensorBoard ---\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "device_tb = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"TensorBoard section using device: {device_tb}\")\n",
    "\n",
    "tb_config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"optimizer\": \"Adam\",\n",
    "}\n",
    "\n",
    "# --- TensorBoard: 数据准备 --- \n",
    "tb_dataset_loaded = False\n",
    "try:\n",
    "    print(\"TensorBoard: Preparing FashionMNIST dataset...\")\n",
    "    tb_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    tb_trainset = torchvision.datasets.FashionMNIST(root='./data_tb', train=True, download=True, transform=tb_transform)\n",
    "    tb_testset = torchvision.datasets.FashionMNIST(root='./data_tb', train=False, download=True, transform=tb_transform)\n",
    "    tb_trainloader = DataLoader(tb_trainset, batch_size=tb_config['batch_size'], shuffle=True, num_workers=0)\n",
    "    tb_testloader = DataLoader(tb_testset, batch_size=tb_config['batch_size']*2, shuffle=False, num_workers=0)\n",
    "    tb_classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "    print(\"TensorBoard: Dataset prepared.\")\n",
    "    tb_dataset_loaded = True\n",
    "except Exception as e:\n",
    "    print(f\"TensorBoard: Error loading dataset: {e}\")\n",
    "\n",
    "# --- TensorBoard: 模型定义 --- \n",
    "class SimpleCNN_TB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x): return self.network(x)\n",
    "print(\"TensorBoard: SimpleCNN_TB model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TensorBoard: 训练循环与日志记录 ---\n",
    "def train_with_tensorboard(cfg, train_loader, test_loader, classes):\n",
    "    print(\"\\n--- Running Training Loop for TensorBoard --- \")\n",
    "    if not tb_dataset_loaded: return None\n",
    "        \n",
    "    model = SimpleCNN_TB().to(device_tb)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "    \n",
    "    run_name = f\"TB_LR={cfg['learning_rate']}_{int(time.time())}\"\n",
    "    tb_log_dir = os.path.join(\"runs_tb\", run_name)\n",
    "    writer = SummaryWriter(log_dir=tb_log_dir)\n",
    "    print(f\"TB Train: Logging to {writer.log_dir}\")\n",
    "    \n",
    "    global_step = 0\n",
    "    for epoch in range(cfg['epochs']):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device_tb), data[1].to(device_tb)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "            \n",
    "            if i % 400 == 399:\n",
    "                 batch_loss = running_loss / 400\n",
    "                 writer.add_scalar('Loss/train_step_tb', batch_loss, global_step)\n",
    "                 running_loss = 0.0\n",
    "        \n",
    "        # Epoch evaluation & logging\n",
    "        model.eval()\n",
    "        correct, total, test_loss = 0, 0, 0.0\n",
    "        sample_images = None\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loader):\n",
    "                images, labels = data[0].to(device_tb), data[1].to(device_tb)\n",
    "                if batch_idx == 0: sample_images = images.cpu()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        epoch_test_loss = test_loss / len(test_loader)\n",
    "        print(f'TB Run - Epoch {epoch + 1} Test Acc: {epoch_accuracy:.2f}%, Test Loss: {epoch_test_loss:.4f}')\n",
    "        \n",
    "        writer.add_scalar('Accuracy/test_tb', epoch_accuracy, epoch)\n",
    "        writer.add_scalar('Loss/test_tb', epoch_test_loss, epoch)\n",
    "        if epoch == cfg['epochs'] - 1:\n",
    "            if sample_images is not None:\n",
    "                 img_grid = torchvision.utils.make_grid(sample_images[:16], nrow=4)\n",
    "                 writer.add_image('Test_Samples_tb', img_grid, epoch)\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                     writer.add_histogram(f\"Weights_tb/{name.replace('.', '/')}\", param.cpu().data.numpy(), epoch)\n",
    "                     if param.grad is not None: \n",
    "                          writer.add_histogram(f\"Gradients_tb/{name.replace('.', '/')}\", param.cpu().grad.numpy(), epoch)\n",
    "                          \n",
    "    writer.close()\n",
    "    print(\"TB Train: TensorBoard training finished.\")\n",
    "    return model\n",
    "\n",
    "# --- Run Training --- \n",
    "if tb_dataset_loaded:\n",
    "    model_tb = train_with_tensorboard(tb_config, tb_trainloader, tb_testloader, tb_classes)\n",
    "else:\n",
    "    print(\"Skipping TensorBoard training run due to dataset loading error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 查看 TensorBoard UI\n",
    "\n",
    "1.  打开终端。\n",
    "2.  导航到包含 `runs_tb` 的目录。\n",
    "3.  运行 `tensorboard --logdir runs_tb`。\n",
    "4.  在浏览器中打开 `http://localhost:6006/`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Weights & Biases (WandB) 进行跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 WandB 简介与设置\n",
    "WandB 提供云端服务来跟踪实验，需要注册并登录。它通过 `wandb.init()` 开始跟踪，并使用 `wandb.log()` 记录数据。\n",
    "\n",
    "**重要**: 运行下面的代码前，请确保你已经在环境中通过 `wandb login` 登录，或设置了 `WANDB_API_KEY` 环境变量，否则日志记录将处于 `disabled` 模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WandB: 导入与设置 ---\n",
    "print(\"\\n--- Setting up for Weights & Biases ---\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "device_wandb = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"WandB section using device: {device_wandb}\")\n",
    "\n",
    "# --- 配置 (在此部分内定义) ---\n",
    "wandb_config = {\n",
    "    \"learning_rate\": 0.0015,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 128,\n",
    "    \"optimizer\": \"RMSprop\",\n",
    "}\n",
    "\n",
    "# --- 数据准备 (在此部分内执行) --- \n",
    "wandb_dataset_loaded = False\n",
    "try:\n",
    "    print(\"WandB Section: Preparing FashionMNIST dataset...\")\n",
    "    wandb_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    wandb_trainset = torchvision.datasets.FashionMNIST(root='./data_wandb', train=True, download=True, transform=wandb_transform)\n",
    "    wandb_testset = torchvision.datasets.FashionMNIST(root='./data_wandb', train=False, download=True, transform=wandb_transform)\n",
    "    wandb_trainloader = DataLoader(wandb_trainset, batch_size=wandb_config['batch_size'], shuffle=True, num_workers=0)\n",
    "    wandb_testloader = DataLoader(wandb_testset, batch_size=wandb_config['batch_size']*2, shuffle=False, num_workers=0)\n",
    "    wandb_classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                     'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "    print(\"WandB Section: Dataset prepared.\")\n",
    "    wandb_dataset_loaded = True\n",
    "except Exception as e:\n",
    "    print(f\"WandB Section: Error loading dataset: {e}\")\n",
    "\n",
    "# --- 模型定义 (在此部分内定义) --- \n",
    "class SimpleCNN_WandB(nn.Module):\n",
    "    # (模型结构同前)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x): return self.network(x)\n",
    "print(\"WandB Section: SimpleCNN_WandB model defined.\")\n",
    "\n",
    "# Re-check WandB login possibility (defined in first code cell)\n",
    "wandb_mode = \"online\" if 'wandb_online_mode_possible' in globals() and wandb_online_mode_possible else \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- B.3 WandB 训练循环 --- \n",
    "def train_with_wandb(cfg, train_loader, test_loader, classes):\n",
    "    print(\"\\n--- Running Training Loop for WandB --- \")\n",
    "    if not wandb_dataset_loaded: return None\n",
    "        \n",
    "    run_timestamp = int(time.time())\n",
    "    run_name = f\"WandB_{cfg['optimizer']}_lr{cfg['learning_rate']}_{run_timestamp}\"\n",
    "    \n",
    "    wandb_run = None\n",
    "    try:\n",
    "        wandb_run = wandb.init(\n",
    "            project=\"pytorch-tracking-tutorial-revised\", \n",
    "            config=cfg, name=run_name, reinit=True, mode=wandb_mode\n",
    "        )\n",
    "        print(f\"WandB Train: Run initialized (mode: {wandb_mode}). URL: {wandb_run.url if wandb_run and wandb_mode == 'online' else 'N/A'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"WandB Train: Could not initialize WandB: {e}. Aborting training for WandB.\")\n",
    "        return None\n",
    "\n",
    "    model = SimpleCNN_WandB().to(device_wandb)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if wandb.config.optimizer == 'Adam':\n",
    "         optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "    else:\n",
    "         optimizer = optim.RMSprop(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "    if wandb_mode == 'online':\n",
    "        wandb.watch(model, log=\"all\", log_freq=100)\n",
    "        \n",
    "    global_step = 0\n",
    "    for epoch in range(wandb.config.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device_wandb), data[1].to(device_wandb)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "            \n",
    "            if i % 400 == 399:\n",
    "                batch_loss = running_loss / 400\n",
    "                if wandb_mode == 'online':\n",
    "                    wandb.log({\"step_loss_wandb\": batch_loss, \"global_step_wandb\": global_step})\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # Epoch evaluation & logging\n",
    "        model.eval()\n",
    "        correct, total, test_loss = 0, 0, 0.0\n",
    "        sample_images, sample_labels, sample_preds = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loader):\n",
    "                images, labels = data[0].to(device_wandb), data[1].to(device_wandb)\n",
    "                if batch_idx == 0: \n",
    "                    sample_images = images.cpu()\n",
    "                    sample_labels = labels.cpu()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                if batch_idx == 0:\n",
    "                    sample_preds = predicted.cpu()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        epoch_test_loss = test_loss / len(test_loader)\n",
    "        print(f'WandB Run - Epoch {epoch + 1} Test Acc: {epoch_accuracy:.2f}%, Test Loss: {epoch_test_loss:.4f}')\n",
    "        \n",
    "        if wandb_mode == 'online':\n",
    "            wandb_logs = {\"epoch\": epoch + 1, \"test_accuracy_wandb\": epoch_accuracy, \"test_loss_wandb\": epoch_test_loss}\n",
    "            if len(sample_images) > 0:\n",
    "                 wandb_images = []\n",
    "                 num_samples_to_log = min(16, len(sample_images))\n",
    "                 for idx in range(num_samples_to_log):\n",
    "                     wandb_images.append(wandb.Image(\n",
    "                         sample_images[idx],\n",
    "                         caption=f\"Pred: {classes[sample_preds[idx]]}, True: {classes[sample_labels[idx]]}\"\n",
    "                     ))\n",
    "                 wandb_logs[\"test_samples_wandb\"] = wandb_images\n",
    "            wandb.log(wandb_logs)\n",
    "            \n",
    "    if wandb_run:\n",
    "        wandb_run.finish()\n",
    "    print(\"WandB Train: WandB training finished.\")\n",
    "    return model\n",
    "\n",
    "# --- Run Training with WandB ---\n",
    "if wandb_dataset_loaded:\n",
    "    model_wandb = train_with_wandb(wandb_config, wandb_trainloader, wandb_testloader, wandb_classes)\n",
    "else:\n",
    "    print(\"Skipping WandB training run due to dataset loading error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 查看 WandB Dashboard\n",
    "\n",
    "1.  如果 `wandb_mode` 是 `online`，访问你的 WandB 账户 ([https://wandb.ai/](https://wandb.ai/))。\n",
    "2.  找到名为 `pytorch-tracking-tutorial-revised` 的项目。\n",
    "3.  查看对应的 run。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C: 使用 MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 MLflow Tracking 简介\n",
    "MLflow Tracking 用于记录实验运行的参数、指标和 Artifacts。它可以将日志保存到本地 `mlruns` 目录或配置远程服务器。\n",
    "\n",
    "**核心步骤**：\n",
    "1. `mlflow.set_experiment()`: 设置实验名称。\n",
    "2. `with mlflow.start_run():`: 开始一个运行。\n",
    "3. 在 `with` 块内使用 `mlflow.log_*` 方法记录信息。\n",
    "4. `mlflow.pytorch.log_model()`: (可选) 记录 PyTorch 模型。\n",
    "5. 在终端运行 `mlflow ui` 查看结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- C.2 MLflow 设置与导入 ---\n",
    "print(\"\\n--- Setting up for MLflow ---\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # For logging plot artifact\n",
    "import os\n",
    "import time\n",
    "\n",
    "device_mlflow = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"MLflow section using device: {device_mlflow}\")\n",
    "\n",
    "# --- 配置 (在此部分内定义) ---\n",
    "mlflow_config = {\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"optimizer\": \"SGD\",\n",
    "}\n",
    "\n",
    "# --- 数据准备 (在此部分内执行) --- \n",
    "mlflow_dataset_loaded = False\n",
    "try:\n",
    "    print(\"MLflow Section: Preparing FashionMNIST dataset...\")\n",
    "    mlflow_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    mlflow_trainset = torchvision.datasets.FashionMNIST(root='./data_mlflow', train=True, download=True, transform=mlflow_transform)\n",
    "    mlflow_testset = torchvision.datasets.FashionMNIST(root='./data_mlflow', train=False, download=True, transform=mlflow_transform)\n",
    "    mlflow_trainloader = DataLoader(mlflow_trainset, batch_size=mlflow_config['batch_size'], shuffle=True, num_workers=0)\n",
    "    mlflow_testloader = DataLoader(mlflow_testset, batch_size=mlflow_config['batch_size']*2, shuffle=False, num_workers=0)\n",
    "    mlflow_classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                      'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "    print(\"MLflow Section: Dataset prepared.\")\n",
    "    mlflow_dataset_loaded = True\n",
    "except Exception as e:\n",
    "    print(f\"MLflow Section: Error loading dataset: {e}\")\n",
    "\n",
    "# --- 模型定义 (在此部分内定义) --- \n",
    "class SimpleCNN_MLflow(nn.Module):\n",
    "    # (模型结构同前)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x): return self.network(x)\n",
    "print(\"MLflow Section: SimpleCNN_MLflow model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- C.3 MLflow 训练循环 --- \n",
    "def train_with_mlflow(cfg, train_loader, test_loader, classes):\n",
    "    print(\"\\n--- Running Training Loop for MLflow --- \")\n",
    "    if not mlflow_dataset_loaded: return None\n",
    "\n",
    "    mlflow.set_experiment(\"FashionMNIST Classification Revised\")\n",
    "    run_timestamp = int(time.time())\n",
    "    run_name = f\"MLflow_{cfg['optimizer']}_lr{cfg['learning_rate']}_{run_timestamp}\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        print(f\"MLflow Train: Run started. Run ID: {run.info.run_id}\")\n",
    "        mlflow.log_params(cfg)\n",
    "        \n",
    "        model = SimpleCNN_MLflow().to(device_mlflow)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=cfg['learning_rate'], momentum=0.9)\n",
    "\n",
    "        global_step = 0\n",
    "        final_epoch_accuracy = 0 \n",
    "        for epoch in range(cfg['epochs']):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                inputs, labels = data[0].to(device_mlflow), data[1].to(device_mlflow)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                global_step += 1\n",
    "                \n",
    "                if i % 400 == 399:\n",
    "                    batch_loss = running_loss / 400\n",
    "                    mlflow.log_metric(\"step_loss_mlflow\", batch_loss, step=global_step)\n",
    "                    running_loss = 0.0\n",
    "            \n",
    "            # Epoch evaluation & logging\n",
    "            model.eval()\n",
    "            correct, total, test_loss = 0, 0, 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data[0].to(device_mlflow), data[1].to(device_mlflow)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    test_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_accuracy = 100 * correct / total\n",
    "            epoch_test_loss = test_loss / len(test_loader)\n",
    "            final_epoch_accuracy = epoch_accuracy\n",
    "            print(f'MLflow Run - Epoch {epoch + 1} Test Acc: {epoch_accuracy:.2f}%, Test Loss: {epoch_test_loss:.4f}')\n",
    "            \n",
    "            mlflow.log_metric(\"test_accuracy_mlflow\", epoch_accuracy, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss_mlflow\", epoch_test_loss, step=epoch)\n",
    "\n",
    "        # --- End of Training (within 'with' block) ---\n",
    "        print(\"MLflow Train: Logging model and artifacts...\")\n",
    "        mlflow.pytorch.log_model(model, \"model_mlflow\")\n",
    "        mlflow.log_metric(\"final_accuracy\", final_epoch_accuracy)\n",
    "        \n",
    "        # Log a simple config file as artifact\n",
    "        cfg_path = \"mlflow_config.txt\"\n",
    "        with open(cfg_path, \"w\") as f: f.write(str(cfg))\n",
    "        mlflow.log_artifact(cfg_path)\n",
    "        if os.path.exists(cfg_path): os.remove(cfg_path) \n",
    "        \n",
    "    print(f\"MLflow Train: MLflow run finished. Run ID: {run.info.run_id}\")\n",
    "    return model\n",
    "\n",
    "# --- Run Training with MLflow ---\n",
    "if mlflow_dataset_loaded:\n",
    "    model_mlflow = train_with_mlflow(mlflow_config, mlflow_trainloader, mlflow_testloader, mlflow_classes)\n",
    "else:\n",
    "    print(\"Skipping MLflow training run due to dataset loading error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.4 查看 MLflow UI\n",
    "\n",
    "1.  打开终端。\n",
    "2.  导航到包含 `mlruns` 的目录。\n",
    "3.  运行 `mlflow ui`。\n",
    "4.  在浏览器中打开 `http://localhost:5000`。\n",
    "5.  找到名为 `FashionMNIST Classification Revised` 的实验查看运行结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比较与总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较与总结\n",
    "\n",
    "本教程分别独立地展示了如何使用 TensorBoard, Weights & Biases, 和 MLflow Tracking 来跟踪和可视化一个简单的 PyTorch 训练过程。每个工具都有其独特的优势和适用场景。\n",
    "\n",
    "| 特性             | TensorBoard                     | Weights & Biases (WandB)            | MLflow Tracking                |\n",
    "|------------------|---------------------------------|-------------------------------------|--------------------------------|\n",
    "| **类型**         | 开源可视化工具包                 | 商业云平台 (个人/学术免费)          | 开源 MLOps 平台 (Tracking组件) |\n",
    "| **核心功能**     | 实时监控, 可视化 (图, 图表, 嵌入)| 实验跟踪, 可视化, 协作, 模型管理 | 实验跟踪, 参数/指标/代码/模型记录 |\n",
    "| **设置**         | 简单 (通常随框架安装)             | 需要注册登录, `pip install wandb` | `pip install mlflow`, 可本地运行 |\n",
    "| **UI 托管**      | 本地运行 `tensorboard` 命令     | 云端仪表板                          | 本地运行 `mlflow ui` 或远程服务器 |\n",
    "| **协作**         | 有限 (共享日志文件)             | 强大 (团队, 报告, 项目)           | 良好 (共享 Tracking Server)      |\n",
    "| **集成**         | PyTorch, TensorFlow, JAX 等     | PyTorch, TF, Keras, Sklearn, XGBoost等 | 多种框架 (PyTorch, TF, Sklearn等) |\n",
    "| **超参数扫描**   | HParams 插件 (较基础)           | 内置强大的 Sweeps 功能              | 需要与其他库 (如 Hyperopt) 集成  |\n",
    "| **模型/数据版本**| 不直接支持                      | 支持 Artifacts (版本化)             | 支持 Artifacts (版本化)          |\n",
    "| **部署/注册**    | 无                              | 有限 (集成部署工具)                 | MLflow Models & Registry      |\n",
    "\n",
    "**选择建议**: \n",
    "*   **TensorBoard**: 快速本地可视化和调试训练过程的首选。\n",
    "*   **WandB**: 需要强大云端协作、高级可视化和集成超参数扫描时非常好用。\n",
    "*   **MLflow**: 适合需要开源、可自托管、关注实验复现性、代码/模型版本管理和 MLOps 集成的场景。\n",
    "\n",
    "选择哪个工具取决于你的具体需求和工作流程偏好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}